{
  "record": {
    "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
    "filename": "142f457d-1727-4142-a492-05845eb065d9.pdf",
    "num_pages": 7,
    "processed_at": "2025-12-12 18:19:36.946166"
  },
  "sections": [
    {
      "section_id": "97379b84-9352-4900-8083-246246920d5a",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "Root",
      "level": 0,
      "page_start": 1,
      "page_end": 7,
      "parent_section_id": null,
      "child_section_ids": [
        "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
        "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
        "6dbd69d4-64cf-4e38-a9cb-24cc5259d1f4",
        "b815b072-5c71-492e-a19e-3b48c618eafe",
        "6270cb10-b1be-46f2-80bd-afb2981f4d20",
        "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
        "98c0ae99-ae54-4838-9662-59de83afaa45",
        "9e35d1e1-c886-41d4-8cdc-a876cbb44b80",
        "e4c6d421-f9ef-4177-acfe-913ad81143cc",
        "e3c10367-4b92-4f36-a112-cc1ea107ac8f",
        "7ba46241-369f-40e0-9417-4e8467f7042f",
        "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
        "0e4d27c9-7f70-4d9d-8898-bb69ccdbca72",
        "fceaa985-4c43-4311-bca8-f40dbf36f47d",
        "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61"
      ],
      "block_ids": [],
      "summary": null
    },
    {
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "Traffic Accident Risk Forecasting using Contextual Vision Transformers",
      "level": 1,
      "page_start": 1,
      "page_end": 1,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "00da8d34-407d-482c-b176-591e3b6bd858",
        "29c3d22a-5661-469a-9d87-a6fd6e09042a",
        "692f2a12-8cb7-4db3-b686-72c98d3b02c4",
        "41626654-44ed-4be0-b93f-8bb40f6e375d",
        "5a606e2c-f730-4138-b87d-ce7ddf34b341",
        "08bd2ce5-9039-4d43-bf2d-79174fb534b6",
        "663bd57c-810f-4306-95e0-d03324b83223",
        "2d8dcf50-e799-442e-b7b2-3ef1a2ebb1e9",
        "51c50b1c-9888-4266-9198-5c8e0bf772ba"
      ],
      "summary": null
    },
    {
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "I. INTRODUCTION",
      "level": 1,
      "page_start": 1,
      "page_end": 1,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "45d24534-00ef-482c-a5cb-bbdab0858761",
        "d7acbf75-7004-4776-afeb-056c31c33465",
        "908f4902-988c-4f28-a27a-c82655144dc1",
        "bce66f1b-4745-4fbe-9cf6-ca39616a7675",
        "9928c3c7-26ec-4736-8fd5-7a84de2b3cd7",
        "02299c8e-6d8b-4340-9071-dff67b4d9f59",
        "7b75fef3-a6af-452c-b41a-25241c9c4bbe",
        "d1aa96cc-bed5-4c69-88a9-529e326bd2ba",
        "1530fa72-d525-4fbe-ad36-79d58450574e",
        "73120c31-de73-4183-ac19-509ec98559fc",
        "e37e6310-0073-4939-8c60-1339ffadec74",
        "cf9b0bd2-73c6-4d45-90fb-edbcf4676dac",
        "90d9b838-054d-4172-9da5-228231fbcde4",
        "266cca58-264a-4787-818f-10702131fd79",
        "210fc51d-1d6b-49bb-a4d7-6331c0b66717"
      ],
      "summary": null
    },
    {
      "section_id": "6dbd69d4-64cf-4e38-a9cb-24cc5259d1f4",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "II. METHODOLOGY",
      "level": 1,
      "page_start": 2,
      "page_end": 2,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "3e0a563f-5296-40b6-aea5-2a343096a051"
      ],
      "summary": null
    },
    {
      "section_id": "b815b072-5c71-492e-a19e-3b48c618eafe",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "A. Definitions",
      "level": 1,
      "page_start": 2,
      "page_end": 2,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "7ce59324-f296-4a09-9815-b7faa786c178",
        "50c8f171-1a65-4ebd-b7ff-a969647aee91"
      ],
      "summary": null
    },
    {
      "section_id": "6270cb10-b1be-46f2-80bd-afb2981f4d20",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "B. Problem Formulation",
      "level": 1,
      "page_start": 2,
      "page_end": 2,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "4cdd1fda-2502-4b85-b854-b964a8b7640a"
      ],
      "summary": null
    },
    {
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "C. Contextual Vision Transformer (C-ViT) Model",
      "level": 1,
      "page_start": 3,
      "page_end": 3,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "b6afc435-8847-4985-b247-f7a7992e0060",
        "b5534d2d-e527-486f-bf16-19e9c2f70116",
        "174bde62-d0be-4c17-825f-251a91ec9936",
        "54439462-d117-4a8c-b578-7853fef2ed33",
        "2e076b9f-bc98-4bbd-86c2-a3135d30f596",
        "9fa94617-8749-4b8f-835a-958bebd9569c",
        "3d750bab-8d41-434e-ac40-225388c64da7",
        "fb57e1eb-e426-476e-ac1e-b0f3dc68ede1",
        "a0eb8bbf-059f-40d8-80f0-8d1c131737ca"
      ],
      "summary": null
    },
    {
      "section_id": "98c0ae99-ae54-4838-9662-59de83afaa45",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "III. EXPERIMENTS AND RESULTS",
      "level": 1,
      "page_start": 4,
      "page_end": 4,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "9862422d-f3bf-4cb0-9dda-9bfcae20dcc5"
      ],
      "summary": null
    },
    {
      "section_id": "9e35d1e1-c886-41d4-8cdc-a876cbb44b80",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "A. Datasets",
      "level": 1,
      "page_start": 4,
      "page_end": 4,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "fb9f1f43-1c71-40b0-9d90-febeb6f27066",
        "cf3b361b-5c37-4477-9204-073f8bdd2b4c",
        "898edb2f-182c-4cdd-b388-8cd9c673d6be",
        "a8444eb5-67e1-4eef-a959-42ab8257af0c"
      ],
      "summary": null
    },
    {
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "B. Experiment Setup",
      "level": 1,
      "page_start": 4,
      "page_end": 4,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "77d8fdf0-4e23-46a9-848e-04e65d00bcdb",
        "b7bff769-6d71-4c82-b1be-a97987a13735",
        "cd817528-b256-4041-a6b8-4eccf7330acd",
        "0b2ec380-e00e-4cda-af4c-08b58c9c72e3"
      ],
      "summary": null
    },
    {
      "section_id": "e3c10367-4b92-4f36-a112-cc1ea107ac8f",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "C. Evaluation Metrics",
      "level": 1,
      "page_start": 5,
      "page_end": 5,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "ab44bdc4-7aa6-4f8d-890f-c12e782a3dd7",
        "57fa3b57-4752-4981-9049-7c63cfc26769",
        "652236eb-c94f-4d88-a5c8-ec3c59db114a"
      ],
      "summary": null
    },
    {
      "section_id": "7ba46241-369f-40e0-9417-4e8467f7042f",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "D. Baselines",
      "level": 1,
      "page_start": 5,
      "page_end": 5,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "a5f232a4-fd26-48fb-a6d9-8c86970d759f",
        "fb8f4982-735d-47d7-b7df-a935e905e24d",
        "0bbcee85-dcd2-47d4-be6d-fa73fe919a56",
        "751fc987-8358-4015-81ad-5b63b8522058",
        "ad9582f0-50e4-493c-93a2-6628ad621f23",
        "bacbf4fa-f92e-4253-9b3d-e68a57f8d71b"
      ],
      "summary": null
    },
    {
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "E. Results",
      "level": 1,
      "page_start": 5,
      "page_end": 5,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "16171c7d-ffa2-4df0-8bbc-82e37d5ff9dc",
        "1c70b254-f3ef-42d7-8e8d-dd56d8a91ba3",
        "a716ca98-2145-49d0-a3f9-a11d2f97447b",
        "2b48353c-2731-4e94-ba28-79031a433e1f",
        "5dc9fd4d-598b-4a07-9af6-5038db9d57df",
        "47e900e9-db9e-4efa-84e9-104490c30e16",
        "24637bcb-ac59-4820-b36b-355617758dc6",
        "e87fe9a0-509f-455e-bea1-e27f9226c4eb"
      ],
      "summary": null
    },
    {
      "section_id": "0e4d27c9-7f70-4d9d-8898-bb69ccdbca72",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "IV. CONCLUSION",
      "level": 1,
      "page_start": 6,
      "page_end": 6,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "56bd1d9e-428d-4ba8-b399-6e3756064252"
      ],
      "summary": null
    },
    {
      "section_id": "fceaa985-4c43-4311-bca8-f40dbf36f47d",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "ACKNOWLEDGMENTS",
      "level": 1,
      "page_start": 6,
      "page_end": 6,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "48e22294-516a-4da0-9426-08152900067c"
      ],
      "summary": null
    },
    {
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "title": "REFERENCES",
      "level": 1,
      "page_start": 6,
      "page_end": 6,
      "parent_section_id": "97379b84-9352-4900-8083-246246920d5a",
      "child_section_ids": [],
      "block_ids": [
        "7c39f06f-84db-4d9c-9529-da16874aac03",
        "18e23cb7-c35a-4144-bfa7-8f6eef517e47",
        "e216c1f3-a9e4-4769-97db-e5688c05754d",
        "d710869e-83d5-4880-bc69-920c9ef74e55",
        "88149e8c-7c8b-4f50-b1bd-c9ad5e6db3e2",
        "618cc3ed-bc3e-4716-975c-69f333950ac0",
        "d6312a35-0b50-4968-9900-c30d8e8e20d0",
        "b83c490a-d7f7-431c-803c-a39a072ae171",
        "318c433a-588e-470c-aa3b-3740724db43f",
        "407a4bf8-882e-4dfc-9526-ff83546cb23c",
        "2ca34611-9f97-4700-a5d3-e1402b65f41b",
        "ea370ccb-1b60-46e3-a998-4e296ec55e34",
        "f79b9cee-e434-4f22-a70d-d725e52ad602",
        "55ef998d-2881-4f37-ad9e-cd0557dd2ef6",
        "f8a56c93-b06c-4904-b976-dbf9f7e83def",
        "3652f1e6-e347-4443-935b-d7873e1f1b46",
        "bae45e18-646d-4488-8f5a-d9f8a588f9ee",
        "fb4e9215-2eb6-4999-aebf-6949099bfc2a",
        "68cbd1fe-dc49-469d-80fb-a0e2593f3db4",
        "602834b5-8eaa-42e8-9161-27392a24bc0c",
        "5bfc1d61-61ca-4360-b2e7-8d8dc53e6eb7"
      ],
      "summary": null
    }
  ],
  "blocks": [
    {
      "block_id": "00da8d34-407d-482c-b176-591e3b6bd858",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "element_type": "paragraph",
      "content": "1 st Khaled Saleh",
      "image_ids": []
    },
    {
      "block_id": "29c3d22a-5661-469a-9d87-a6fd6e09042a",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "element_type": "paragraph",
      "content": "Faculty of Engineering and IT University of Technology Sydney",
      "image_ids": []
    },
    {
      "block_id": "692f2a12-8cb7-4db3-b686-72c98d3b02c4",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "element_type": "paragraph",
      "content": "Sydney, Australia khaled.aboufarw@uts.edu.au",
      "image_ids": []
    },
    {
      "block_id": "41626654-44ed-4be0-b93f-8bb40f6e375d",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "element_type": "paragraph",
      "content": "2 rd Artur Grigorev",
      "image_ids": []
    },
    {
      "block_id": "5a606e2c-f730-4138-b87d-ce7ddf34b341",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "element_type": "paragraph",
      "content": "Faculty of Engineering and IT University of Technology Sydney",
      "image_ids": []
    },
    {
      "block_id": "08bd2ce5-9039-4d43-bf2d-79174fb534b6",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "element_type": "paragraph",
      "content": "Sydney, Australia",
      "image_ids": []
    },
    {
      "block_id": "663bd57c-810f-4306-95e0-d03324b83223",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "element_type": "paragraph",
      "content": "ORCID: 0000-0001-6875-3568",
      "image_ids": []
    },
    {
      "block_id": "2d8dcf50-e799-442e-b7b2-3ef1a2ebb1e9",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "element_type": "paragraph",
      "content": "Abstract -Recently, the problem of traffic accident risk forecasting has been getting the attention of the intelligent transportation systems community due to its significant impact on traffic clearance. This problem is commonly tackled in the literature by using data-driven approaches that model the spatial and temporal incident impact, since they were shown to be crucial for the traffic accident risk forecasting problem. To achieve this, most approaches build different architectures to capture the spatio-temporal correlations features, making them inefficient for large traffic accident datasets. Thus, in this work, we are proposing a novel unified framework, namely a contextual vision transformer, that can be trained in an end-to-end approach which can effectively reason about the spatial and temporal aspects of the problem while providing accurate traffic accident risk predictions. We evaluate and compare the performance of our proposed methodology against baseline approaches from the literature across two large-scale traffic accident datasets from two different geographical locations. The results have shown a significant improvement with roughly 2% in RMSE score in comparison to previous state-of-art works (SoTA) in the literature. Moreover, our proposed approach has outperformed the SoTA technique over the two datasets while only requiring 23x fewer computational requirements.",
      "image_ids": []
    },
    {
      "block_id": "51c50b1c-9888-4266-9198-5c8e0bf772ba",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "element_type": "paragraph",
      "content": "Index Terms -traffic accident risk; risk prediction; vision transformers; deep learning",
      "image_ids": []
    },
    {
      "block_id": "45d24534-00ef-482c-a5cb-bbdab0858761",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "Traffic accidents represent a major concern for cities around the world due to a significant economical and health impact to their populations. The number of vehicles has been substantially increasing during the past decades, especially in developing countries, which lead to an increase in the number of traffic accidents [1]. The National Highway Traffic Safety Administration (NHTSA) reports more than 5 million traffic accidents happening in the United States each year [2]. The World Health Organization also reported 1.35 million fatalities happening worldwide which resulted from traffic accidents in 2016 [3].",
      "image_ids": []
    },
    {
      "block_id": "d7acbf75-7004-4776-afeb-056c31c33465",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "In the past years, traffic accident research has seen an increased use of computational methods. Different problems were addressed, including: 1) traffic accident duration prediction methods, [4] 2) accident detection [5], 3) estimation of severity, and more recently, a development of spatialtemporal modelling methods have allowed to perform accident risk prediction using high-dimensional spatial, semantic and temporal data sets [6]. The use of such methods has enhanced the automated analysis of traffic data together with",
      "image_ids": []
    },
    {
      "block_id": "908f4902-988c-4f28-a27a-c82655144dc1",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "3 nd Adriana-Simona Mih\u02d8 ait \u00b8\u02d8 a",
      "image_ids": []
    },
    {
      "block_id": "bce66f1b-4745-4fbe-9cf6-ca39616a7675",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "Faculty of Engineering and IT University of Technology Sydney",
      "image_ids": []
    },
    {
      "block_id": "9928c3c7-26ec-4736-8fd5-7a84de2b3cd7",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "Sydney, Australia",
      "image_ids": []
    },
    {
      "block_id": "02299c8e-6d8b-4340-9071-dff67b4d9f59",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "ORCID: 0000-0001-7670-5777",
      "image_ids": []
    },
    {
      "block_id": "7b75fef3-a6af-452c-b41a-25241c9c4bbe",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "image",
      "content": "[IMAGE: ]",
      "image_ids": [
        "dc5bdc1c-c8f8-45e6-9129-b8b9c2590ec5"
      ]
    },
    {
      "block_id": "d1aa96cc-bed5-4c69-88a9-529e326bd2ba",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "Figure 1. City grid representation for our study.",
      "image_ids": []
    },
    {
      "block_id": "1530fa72-d525-4fbe-ad36-79d58450574e",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "the increasing number of publicly available data sets. Traffic accident risk prediction allows to: 1) detect high-risk areas within a traffic network, which may facilitate the decisionmaking inside traffic management authorities, 2) to allocate resources and assess the road design to reduce the number of accidents in the future, 3) to predict timely high-risk situations on the road and 4) to allow an implementation of risk-reducing traffic management strategies.",
      "image_ids": []
    },
    {
      "block_id": "73120c31-de73-4183-ac19-509ec98559fc",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "In the literature, the traffic accident risk forecasting problem is commonly formulated as a time-series forecasting task, where given past historical traffic accidents data for a certain city/region, along with an optional contextual information about those accidents, the objective is to forecast/predict the future traffic accident risk for that city/region. Since the nature of the traffic accident risk problem implicitly involves two types of modelling, e.g. the spatial approach (working on the affected geographic region) and the temporal approach (applied over a period of time), thus this problem is often tackled using at least two different types of model architectures.",
      "image_ids": []
    },
    {
      "block_id": "e37e6310-0073-4939-8c60-1339ffadec74",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "One of the first works on traffic accident risk prediction using Deep Learning has been performed with human mobility data using a Stack Denoise Autoencoder (SDAE) on the Japan traffic network [7], but traffic flow and time-related matters (including periodicity) were not considered. Another research [8] relied on the LSTM network to improve the risk prediction in comparison to SAE by considering in addition the air quality, traffic flow and the weather data, represented as short-term and periodic components. [9] proposed also a Coarse and Fine grained prediction on the target accident risk map. RiskOracle [10] relied on Graph-Convolution network, utilizing hierarchical coarse-to-fine modelling and proposing minute-level predictions in comparison to day-level [11] and",
      "image_ids": []
    },
    {
      "block_id": "cf9b0bd2-73c6-4d45-90fb-edbcf4676dac",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "image",
      "content": "[IMAGE: ]",
      "image_ids": [
        "390c77ac-0d33-4384-978c-d223d7e6dc0f"
      ]
    },
    {
      "block_id": "90d9b838-054d-4172-9da5-228231fbcde4",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "Figure 2. The building blocks of our proposed C-ViT model.",
      "image_ids": []
    },
    {
      "block_id": "266cca58-264a-4787-818f-10702131fd79",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "hour-level [7]. In [11] authors have constructed over the ConvLSTM by highlighting the spatial heterogeneity problem and proposing an ensemble of region-specific ConvLSTM models (Hetero-ConvLSTM); they considered weather, the environment and the road condition in Iowa, US for over 8 years of observations, but POIs were not considered. Semantic features, coarse and fine grained risk maps were considered in [12], where also Graph-convolution neural networks and attention-based LSTMs were used. A more recent work in [6] represents the State-of-Art (SoTA) in the field of accident risk prediction, where the authors propose a weighted loss function to address the zero-inflated issue (increase in the number of zero-risk grid cells due to the increase in the granularity of predictions) and making ensemble of models by processing semantic and geo features. So far, risk accident prediction relied mostly upon graph-based methods and spatial-temporal modelling. While this approach worked for limited case study applications, we highly believe that in order to scale it up, this approach can benefit from using visual analysis techniques. Thus, in this work we are re-formulating the problem of traffic accident risk forecasting and we are proposing a novel approach inspired by one of the recent best performing deep learning based architectures for computer vision tasks, the vision transformers [13]. In our proposed model we jointly model and take into account the spatio-temporal nature of the traffic accident risk forecasting problem as well as the influence of contextual information on it using a single unified end-to-end model.",
      "image_ids": []
    },
    {
      "block_id": "210fc51d-1d6b-49bb-a4d7-6331c0b66717",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "element_type": "paragraph",
      "content": "In Section II, a detailed description about the proposed methodology will be presented. Then, in Section III, we will introduce the datasets we utilised for training and evaluating the performance of our approach, the experiments setup and the baseline approaches from the literature we compared our approach against. Finally, in Section IV, we conclude our paper.",
      "image_ids": []
    },
    {
      "block_id": "3e0a563f-5296-40b6-aea5-2a343096a051",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "6dbd69d4-64cf-4e38-a9cb-24cc5259d1f4",
      "element_type": "paragraph",
      "content": "In this section, we will first start with definitions and the problem formulation for the traffic accident risk forecasting task. Then, we will present and discuss the details of our proposed contextual vision transformer (C-ViT) model (as shown in Fig. 2).",
      "image_ids": []
    },
    {
      "block_id": "7ce59324-f296-4a09-9815-b7faa786c178",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "b815b072-5c71-492e-a19e-3b48c618eafe",
      "element_type": "paragraph",
      "content": "Grid Representation: Given a city area bounded by certain latitude and longitude coordinates, we partition it into a grid form with I rows \u00d7 J columns (as shown in Fig. 1), where each cell share the same size.",
      "image_ids": []
    },
    {
      "block_id": "50c8f171-1a65-4ebd-b7ff-a969647aee91",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "b815b072-5c71-492e-a19e-3b48c618eafe",
      "element_type": "paragraph",
      "content": "Traffic Accident Risk: At any given time t , the traffic accident risk Y i t for a grid cell i is defined by the summation of the different types of traffic accidents occurred at that grid cell. Similar to [6], we have three types of traffic accidents and each one has a corresponding value, namely a minor accident has a value of 1, an injured accident a value of 2 and a fatal accident has a value of 3. For instance, if a grid cell incurred three fatal accidents and two minor accidents, the traffic accident risk for it then would be 11.",
      "image_ids": []
    },
    {
      "block_id": "4cdd1fda-2502-4b85-b854-b964a8b7640a",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "6270cb10-b1be-46f2-80bd-afb2981f4d20",
      "element_type": "paragraph",
      "content": "In our formulation of the traffic accident prediction problem, we re-cast it as an image regression task instead of the traditional formulation as a time-series prediction task. This new formulation enables us to natively model the spatiotemporal nature of the traffic accident prediction problem in an end-to-end fashion without the need to have a combination of more than one architecture to address it. To that end, given historical observations in the form of a traffic accident risk map Z 1: T , where Z \u2208 R I \u00d7 J over time period [ 1 : T ] , we represent these observations as an image X with a resolution of I \u00d7 J and its number of channels to be T . Then we feed it to our proposed C-ViT model that fuse it together with the historical contextual information C 1: T to predict/regress the future accident risk map in the next hour \u02c6 Y T + 1, where Y \u2208 R I \u00d7 J .",
      "image_ids": []
    },
    {
      "block_id": "b6afc435-8847-4985-b247-f7a7992e0060",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "element_type": "paragraph",
      "content": "Given the aforementioned formulation, we compile the traffic accident risk maps Z 1: T as a unified single image with size T \u00d7 I \u00d7 J , where T is the number of channels, I is the image's height and J is the image's width, which we pass as an input to our proposed novel C-ViT model. Our C-ViT model's architecture is inspired by the recently introduced vision transformer network [13] that has been achieving competitive results to the convolutional neural network (ConvNet) architecture for image classification tasks [13], [14]. The main building blocks of our C-ViT model are three components, namely the historical traffic accident risk map encoding stage, the historical contextual information encoding stage and the transformer encoder stage. In the following we will analyse deeper each component.",
      "image_ids": []
    },
    {
      "block_id": "b5534d2d-e527-486f-bf16-19e9c2f70116",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "element_type": "image",
      "content": "[IMAGE: ]",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "block_id": "174bde62-d0be-4c17-825f-251a91ec9936",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "element_type": "paragraph",
      "content": "Figure 3. Description of the first stage of the historical risk Map encoding. Given a unified single image X , it is then divided into equally-sized image patches that are passed individually to the linear patch embedding layer.",
      "image_ids": []
    },
    {
      "block_id": "54439462-d117-4a8c-b578-7853fef2ed33",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "element_type": "paragraph",
      "content": "Historical Risk Map Encoding: Given the historical risk maps as a unified single image X with size T \u00d7 I \u00d7 J , we first encode it into a representation that could be easily digested and learned using our transformer encoder. As it was shown in [15], transformer encoders can work better with input data as a sequence of tokens. Thus, we divide the unified single image into a sequence of equally sub-images Xp which we refer to it as an image patch sequence. We can think of the image patches as a sub-spatial regions of a number of cells within the city's grid representation that we defined in Section II-B. The rationale behind this patching process is derived by the assumption that grid cells that are spatially closer to each others will have some geographical and spatial correlations that could potentially be exploited by our model for conducting a better traffic accident risk forecasting.",
      "image_ids": []
    },
    {
      "block_id": "2e076b9f-bc98-4bbd-86c2-a3135d30f596",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "element_type": "paragraph",
      "content": "Here Xp has a size of N \u00d7 T \u00d7 P \u00d7 P , where P is the height/width of the image patch and N is the total number of sequences of image patches, which is defined by N = IJ / P 2 . The operation of dividing the unified single image into a sequence of image patches Xp can be shown in Fig. 3. The image patches sequence are then individually passed through a linear embedding layer which is essentially a learn-able linear projection operation in order to get a sequence of trainable flattened image patches of size D , which we refer to as patch embeddings. Additionally, similar to [13], we have an extra learnable embedding token appended before the sequence of patch embeddings to be passed to the transformer encoder and we refer to this embedding as a 'regression token'. The regression token embedding acts as an image representation which its output is transformed inside the transformer encoder into the predicted accident risk map \u02c6 Y T + 1.",
      "image_ids": []
    },
    {
      "block_id": "9fa94617-8749-4b8f-835a-958bebd9569c",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "element_type": "paragraph",
      "content": "Since the transformer encoder does not have the notion of order in its input sequence tokens, an additional position embeddings are added to each patch embedding. There are a number of pathways to define position embedding, and in our current model we follow the formulation introduced in [15]. In this formulation, the position encoding PE vector is defined by using a wide spectrum of frequencies of sine/cosine functions as follows:",
      "image_ids": []
    },
    {
      "block_id": "3d750bab-8d41-434e-ac40-225388c64da7",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "element_type": "paragraph",
      "content": "where a represents the position, and k is the dimension. From the above formulation, once can conclude that for each dimension k of PE vector, it has a corresponding sinusoid that spans a frequency range from 2 p to 10000 \u00b7 2 p . In other words, this will allow the model to be mindful of the order in the sequential patch embedding by using unique relative positions. The dimension of the PE vector is similar to the linear patch embedding layer's dimension which is D .",
      "image_ids": []
    },
    {
      "block_id": "fb57e1eb-e426-476e-ac1e-b0f3dc68ede1",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "element_type": "paragraph",
      "content": "Historical Contextual Information Encoding As discussed in Section II-B, besides the historical accident risk maps, our C-ViT model takes into account also the historical contextual information C 1: T for the city grid representation. In our model and similar to [6], we took into account the following contextual features: 1) the time period of the day, 2) the day of the week, 3) whether the day is a holiday or not, 4) the weather condition (clear, cloud,..etc), 5) the weather temperature, and 6) traffic condition (inflow and outflow). Given those contextual features, we encode them via a learnable linear embedding layer of dimension D , whose output is fused together with the output from the transformer encoder via a concatenation operation.",
      "image_ids": []
    },
    {
      "block_id": "a0eb8bbf-059f-40d8-80f0-8d1c131737ca",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "element_type": "paragraph",
      "content": "Transformer Encoder The main building block of our transformer encoder is the multi-head self-attention module [15]. In total we have six layers inside our transformer encoder. Internally, each layer is composed of a both selfattention head and feed-forward fully connected sub-layers. Additionally, each sub-layer is followed by two residual connections and a normalisation operation. The multi-head self-attention, or the multi-scaled dot-product attention, works based on the mapping between the so-called 'query' vectors and the pair (key, value) vectors. The dimension of the query and key vectors is dk , where the values vector dimension is dv . The attention operation itself is computed by taking the dot-product between the query and the key vectors divided by the square root of dk before finally passing them to the softmax function to get their weights by their values. Since the scaled dot-product attention operation is done multiple times, the queries, keys and values vectors are extended into matrices Q , K , V respectively. The following formula is the description of how the scaled dot-product attention operation is calculated:",
      "image_ids": []
    },
    {
      "block_id": "9862422d-f3bf-4cb0-9dda-9bfcae20dcc5",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "98c0ae99-ae54-4838-9662-59de83afaa45",
      "element_type": "paragraph",
      "content": "In this section, we first present the datasets we utilised for training and evaluating the performance of our proposed approach. Then, we provide the details of the setup for our experiments, the evaluation metrics and the compared baseline approaches from the the literature. Finally, the quantitative and qualitative results of our proposed approach on real-life datasets are evaluated and discussed.",
      "image_ids": []
    },
    {
      "block_id": "fb9f1f43-1c71-40b0-9d90-febeb6f27066",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "9e35d1e1-c886-41d4-8cdc-a876cbb44b80",
      "element_type": "paragraph",
      "content": "In this study we use two publicly available real datasets for the traffic accident risk forecasting problem, namely NYC 1 and Chicago 2 . As it can be seen from Table I, both datasets have historical traffic accidents and historical taxi trips. The historical traffic accident data contains: time, date, location (latitude and longitude), the number of causalities, the weather condition (clear, cloudy, rainy, snowy or mist), the temperature and the road segment data (i.e. road length, width and type). The NYC dataset has an additional Point of interest (POI) data regarding locations (i.e. residence, school, culture facility, recreation, social service, transportation and commercial). The historical taxi trips include the location and times of pick-up and drop-offs and this data is used to calculate the inflow/outflow of the traffic condition in each area.",
      "image_ids": []
    },
    {
      "block_id": "cf3b361b-5c37-4477-9204-073f8bdd2b4c",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "9e35d1e1-c886-41d4-8cdc-a876cbb44b80",
      "element_type": "paragraph",
      "content": "1 https://opendata.cityofnewyork.us/",
      "image_ids": []
    },
    {
      "block_id": "898edb2f-182c-4cdd-b388-8cd9c673d6be",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "9e35d1e1-c886-41d4-8cdc-a876cbb44b80",
      "element_type": "paragraph",
      "content": "2 https://data.cityofchicago.org/",
      "image_ids": []
    },
    {
      "block_id": "a8444eb5-67e1-4eef-a959-42ab8257af0c",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "9e35d1e1-c886-41d4-8cdc-a876cbb44b80",
      "element_type": "paragraph",
      "content": "Table I DATASETS STATISTICS",
      "image_ids": []
    },
    {
      "block_id": "77d8fdf0-4e23-46a9-848e-04e65d00bcdb",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "element_type": "paragraph",
      "content": "Before we train and evaluate our proposed C-ViT model, we first pre-process the two datasets. The first pre-processing stage was to perform a grid representation by dividing each city map of the two datasets (i.e. NYC and Chicago) into equally-sized grid cells each with a dimension of (2 KM \u00d7 2 KM ). Secondly, similar to [6], we group all the accidents that happened in each grid cell based on their location over the reported duration time for each dataset (for each grid cells with no road segments/accidents, we set its traffic accident risk to zero). Thirdly, we split the data-sets into training, validation and testing. The strategy we followed for the splitting is similar to [6], where we use 60% for training, 20% for validation and 20% for testing while making sure that there is no overlapping accidents based on time (i.e. no accident happened in specific grid cell on specific time is shared between the three data splits). It is worth noting that the traffic accidents periodicity according to the two datasets was set to 1 hour. Finally, each data split is standardised by a mean and standard deviation normalisation so that it could help in accelerating the training process.",
      "image_ids": []
    },
    {
      "block_id": "b7bff769-6d71-4c82-b1be-a97987a13735",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "element_type": "paragraph",
      "content": "Regarding the implementation details of our C-ViT model, the size of the historical traffic risk maps X was set to 7 \u00d7 20 \u00d7 20 which corresponds to a total 7 historical traffic accident risks across the city grid with I rows \u00d7 J columns of size 20. Here we chose 7 historical accident risks specifically to conform with the work done in the literature [6], [16] for a fair comparison provided later in the paper. For each grid cell, the 7 historical accident risks comes from the most recent accident risks in past 3 hours in addition to the past accident risks in the last 4 weeks. The prediction horizon for the traffic accident risk was set to 1 (i.e next hour) similar to [6], [16]. The hyper-parameters for our C-ViT model itself were set according to the model performance on the validation split. To that end, the D dimension for the linear patch embedding, the position embedding layer and the linear embedding layer of the historical contextual encoder was set to 64. The resolution of input patches P to the patch embedding layer was set to 5. The number of self-attention heads were set to 8 and the final output fully connected layer of our C-ViT model was set to 128. Since we formulated the traffic accident risk prediction",
      "image_ids": []
    },
    {
      "block_id": "cd817528-b256-4041-a6b8-4eccf7330acd",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "element_type": "paragraph",
      "content": "Table II PERFORMANCE EVALUATION OF OUR C-VIT MODEL AGAINST A NUMBER OF BASELINE APPROACHES FROM THE LITERATURE OVER THE NYC AND CHICAGO DATASETS.",
      "image_ids": []
    },
    {
      "block_id": "0b2ec380-e00e-4cda-af4c-08b58c9c72e3",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "element_type": "paragraph",
      "content": "task as an image regression task, we have therefore optimised our C-ViT model during the training phase using a weighted mean-squared error (MSE) loss function. The reason for using the weighted MSE loss function instead of using the standard MSE loss function, is to try to combat the unbalanced nature of the traffic risk prediction problem, also known as the zeroinflated problem [19]. The procedure for weighting our loss function is motivated by the focal loss introduced in [20], where we holistically divided the total training samples into four distinctive classes based on their traffic accident risk values. Those risk values are (0, 1, 2, \u2265 3). Similar to [6], the loss function weights were set to 0.05, 0.2, 0.25 and 0.5 respectively. In total, we have trained our C-ViT model for 200 epochs using the Adam optimiser with a learning rate of 0.003 and the batch size was set to 32.",
      "image_ids": []
    },
    {
      "block_id": "ab44bdc4-7aa6-4f8d-890f-c12e782a3dd7",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "e3c10367-4b92-4f36-a112-cc1ea107ac8f",
      "element_type": "paragraph",
      "content": "In order to evaluate the performance of our trained C-ViT model, we utilised the three commonly used metrics for the traffic accident risk prediction task [6], [21], namely root mean squared error (RMSE), Recall and mean average precision (MAP). The three evaluation metrics are calculated as follows:",
      "image_ids": []
    },
    {
      "block_id": "57fa3b57-4752-4981-9049-7c63cfc26769",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "e3c10367-4b92-4f36-a112-cc1ea107ac8f",
      "element_type": "paragraph",
      "content": "where N is the total number of samples to be evaluated, Yn , \u02c6 Yn are the ground truth and the predicted risk values for all grid cells of sample n respectively. An corresponds to the set of grid cells of sample n that have an actual/true traffic accident risk values. Hn corresponds to the set of grid cells within An with the highest traffic accident risk values. On the other hand, PR ( j ) corresponds to the precision of the grid cells starting at 1 and ending at grid cell j . Similarly, REC ( j ) corresponds to the recall value for grid cell j which is set to 1 in case there was a traffic accident risk at it and set to 0 otherwise.",
      "image_ids": []
    },
    {
      "block_id": "652236eb-c94f-4d88-a5c8-ec3c59db114a",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "e3c10367-4b92-4f36-a112-cc1ea107ac8f",
      "element_type": "paragraph",
      "content": "Based on the definition of these three evaluation metrics, we can deduce that the lower the score of RMSE is, the better is the quality of prediction coming out of the model. On the other hand, the higher the recall and MAP scores are, the better is the accuracy of the model.",
      "image_ids": []
    },
    {
      "block_id": "a5f232a4-fd26-48fb-a6d9-8c86970d759f",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "7ba46241-369f-40e0-9417-4e8467f7042f",
      "element_type": "paragraph",
      "content": "We have compared the performance of our proposed C-ViT model to 5 different baseline approaches from the literature and in the following we will briefly describe each approach:",
      "image_ids": []
    },
    {
      "block_id": "fb8f4982-735d-47d7-b7df-a935e905e24d",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "7ba46241-369f-40e0-9417-4e8467f7042f",
      "element_type": "list",
      "content": "RNN-GRU [17]: This model is based on one variant of deep recurrent neural networks (RNN), the gated recurrent unit (GRU) model. This model casts the traffic accident risk forecasting problem as a time-series prediction problem and tries to model the temporal dependency among historical traffic accidents risk.",
      "image_ids": []
    },
    {
      "block_id": "0bbcee85-dcd2-47d4-be6d-fa73fe919a56",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "7ba46241-369f-40e0-9417-4e8467f7042f",
      "element_type": "list",
      "content": "SDCAE [16]: This model is based on the stacked denoised convolution auto-encoder architecture, which focuses mainly on capturing/modelling the spatial features between different cells within a city grid area for a better prediction of the traffic accident risk.",
      "image_ids": []
    },
    {
      "block_id": "751fc987-8358-4015-81ad-5b63b8522058",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "7ba46241-369f-40e0-9417-4e8467f7042f",
      "element_type": "list",
      "content": "H-ConvLSTM [11]: As the name implies, this model combines both deep convolution layers with RNN-based LSTM layers to extract the spatio-temporal features of the traffic accident risk problem by having a sliding window over the city's grid cells; this allows to have sub-regions that could potentially capture the heterogeneity among the different types of spatial regions.",
      "image_ids": []
    },
    {
      "block_id": "ad9582f0-50e4-493c-93a2-6628ad621f23",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "7ba46241-369f-40e0-9417-4e8467f7042f",
      "element_type": "list",
      "content": "GCN [18]: This model is a deep learning model that relies on graph convolution neural network to represent the historical traffic accident data as a graph to capture the long-term spatio-temporal dependency among historical traffic accidents risk data.",
      "image_ids": []
    },
    {
      "block_id": "bacbf4fa-f92e-4253-9b3d-e68a57f8d71b",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "7ba46241-369f-40e0-9417-4e8467f7042f",
      "element_type": "list",
      "content": "GSNet [6]: A recent model that learns the complex spatial-temporal correlations of traffic accidents risk by using a combination of GCN, LSTM and attention mechanism. To the best of our knowledge, GSNet is currently the SOTA method on the NYC and Chicago data-sets.",
      "image_ids": []
    },
    {
      "block_id": "16171c7d-ffa2-4df0-8bbc-82e37d5ff9dc",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "element_type": "paragraph",
      "content": "In Table II, we report the results of our C-ViT model in comparison to the aforementioned baseline approaches",
      "image_ids": []
    },
    {
      "block_id": "1c70b254-f3ef-42d7-8e8d-dd56d8a91ba3",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "element_type": "paragraph",
      "content": "Table III PERFORMANCE EVALUATION OF OUR C-VIT MODEL AGAINST A NUMBER OF BASELINE APPROACHES FROM THE LITERATURE OVER THE HIGH FREQUENCY TIMES OF ACCIDENTS IN THE NYC AND CHICAGO DATASETS.",
      "image_ids": []
    },
    {
      "block_id": "a716ca98-2145-49d0-a3f9-a11d2f97447b",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "element_type": "paragraph",
      "content": "from the literature over the total testing splits for both NYC and Chicago data-sets. As it can be noticed, our model has outperformed all the baseline approaches from the literature in terms of RMSE, recall and MAP scores over the two datasets. It is worth noting from the results, that those models (our C-ViT, GSNet, GCN and H-ConvLSTM) which account for the spatio-temporal property of the traffic accident risk prediction problem, are the top performing approaches on the two data-sets.",
      "image_ids": []
    },
    {
      "block_id": "2b48353c-2731-4e94-ba28-79031a433e1f",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "element_type": "image",
      "content": "[IMAGE: ]",
      "image_ids": [
        "85cc7aa9-8ea4-4eb5-8c94-0e1f1b55cc07"
      ]
    },
    {
      "block_id": "5dc9fd4d-598b-4a07-9af6-5038db9d57df",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "element_type": "paragraph",
      "content": "Figure 4. Comparison between our proposed C-ViT model and GSNet [6], in terms of the number of training parameters.",
      "image_ids": []
    },
    {
      "block_id": "47e900e9-db9e-4efa-84e9-104490c30e16",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "element_type": "paragraph",
      "content": "The closest competitor baseline approach to our C-ViT model, was the GSNet, which to the best of our knowledge, was the SOTA on the two data-sets before our proposed approach. As it can be seen, our C-ViT model has improved the RMSE, recall and MAP scores in comparison to GSNet especially across the Chicago dataset by a relatively large margin. Furthermore, our C-ViT has more competitive advantage over GSNet in terms of the efficiency. As it can be shown in Fig. 4, the number of parameters required by our C-ViT model for training are far lower than those needed for GSNet (saving more than 23x parameters) which makes our approach more suitable for real-time deployment.",
      "image_ids": []
    },
    {
      "block_id": "24637bcb-ac59-4820-b36b-355617758dc6",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "element_type": "paragraph",
      "content": "In order to further evaluate the performance of our proposed C-ViT model, in Table III we report the RMSE, recall and MAP scores of our model when compared to all the other baseline approaches over peak hours of frequent traffic accidents that resulted from the testing split of both the NYC and",
      "image_ids": []
    },
    {
      "block_id": "e87fe9a0-509f-455e-bea1-e27f9226c4eb",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "element_type": "paragraph",
      "content": "Chicago data-sets. Those times of high frequency of traffic accidents are essentially during morning/evening rush hours which are within 7:00-9:00 AM and 04:00-07:00 PM. As it can be seen from the reported results, our C-ViT model continues to achieve more robust results than all other compared baseline approaches. This further prove the utility and quality of our proposed approach that it has a consistent performance across different settings.",
      "image_ids": []
    },
    {
      "block_id": "56bd1d9e-428d-4ba8-b399-6e3756064252",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "0e4d27c9-7f70-4d9d-8898-bb69ccdbca72",
      "element_type": "paragraph",
      "content": "In this work, we have presented a novel approach for the task of traffic accident risk forecasting. In our approach we re-formulated the problem as an image regression problem and introduced a unique contextual vision transformer network (C-ViT) that can efficiently model the traffic accident risk forecasting task from both spatial and temporal perspectives. The proposed approach has been evaluated on two publicly available datasets for the traffic accident risk problem. Furthermore, our proposed C-ViT model has been compared against a number of baseline approaches from the literature and it has outperformed them with a large margin while only requiring less than 23 times the number of training parameters.",
      "image_ids": []
    },
    {
      "block_id": "48e22294-516a-4da0-9426-08152900067c",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "fceaa985-4c43-4311-bca8-f40dbf36f47d",
      "element_type": "paragraph",
      "content": "This research is supported by the ARC LP project LP180100114. This research is funded by iMOVE CRC and supported by the Cooperative Research Centres program, an Australian Government initiative.",
      "image_ids": []
    },
    {
      "block_id": "7c39f06f-84db-4d9c-9529-da16874aac03",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "W. H. Organization, Global status report on road safety 2015 . World Health Organization, 2015.",
      "image_ids": []
    },
    {
      "block_id": "18e23cb7-c35a-4144-bfa7-8f6eef517e47",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "N. H. T. S. Administration, Traffic safety facts 2013 . U.S. department of transportation, 2013.",
      "image_ids": []
    },
    {
      "block_id": "e216c1f3-a9e4-4769-97db-e5688c05754d",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "W. H. Organization et al. , 'Global status report on road safety 2018: summary,' World Health Organization, Tech. Rep., 2018.",
      "image_ids": []
    },
    {
      "block_id": "d710869e-83d5-4880-bc69-920c9ef74e55",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "R. Li, F. C. Pereira, and M. E. Ben-Akiva, 'Overview of traffic incident duration analysis and prediction,' European transport research review , vol. 10, no. 2, pp. 1-13, 2018.",
      "image_ids": []
    },
    {
      "block_id": "88149e8c-7c8b-4f50-b1bd-c9ad5e6db3e2",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "A. B. Parsa, H. Taghipour, S. Derrible, and A. K. Mohammadian, 'Realtime accident detection: coping with imbalanced data,' Accident Analysis & Prevention , vol. 129, pp. 202-210, 2019.",
      "image_ids": []
    },
    {
      "block_id": "618cc3ed-bc3e-4716-975c-69f333950ac0",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "B. Wang, Y. Lin, S. Guo, and H. Wan, 'Gsnet: Learning spatial-temporal correlations from geographical and semantic aspects for traffic accident risk forecasting,' in Proceedings of the AAAI Conference on Artificial Intelligence , vol. 35, no. 5, 2021, pp. 4402-4409.",
      "image_ids": []
    },
    {
      "block_id": "d6312a35-0b50-4968-9900-c30d8e8e20d0",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "Q. Chen, X. Song, H. Yamada, and R. Shibasaki, 'Learning deep representation from big and heterogeneous data for traffic accident inference,' in Thirtieth AAAI conference on artificial intelligence , 2016.",
      "image_ids": []
    },
    {
      "block_id": "b83c490a-d7f7-431c-803c-a39a072ae171",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "H. Ren, Y. Song, J. Liu, Y. Hu, and J. Lei, 'A deep learning approach to the prediction of short-term traffic accident risk,' arXiv preprint arXiv:1710.09543 , 2017.",
      "image_ids": []
    },
    {
      "block_id": "318c433a-588e-470c-aa3b-3740724db43f",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "Z. Zhou, Y. Wang, X. Xie, L. Chen, and C. Zhu, 'Foresee urban sparse traffic accidents: A spatiotemporal multi-granularity perspective,' IEEE Transactions on Knowledge and Data Engineering , 2020.",
      "image_ids": []
    },
    {
      "block_id": "407a4bf8-882e-4dfc-9526-ff83546cb23c",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "Z. Zhou, Y. Wang, X. Xie, L. Chen, and H. Liu, 'Riskoracle: a minutelevel citywide traffic accident forecasting framework,' in Proceedings of the AAAI Conference on Artificial Intelligence , vol. 34, no. 01, 2020, pp. 1258-1265.",
      "image_ids": []
    },
    {
      "block_id": "2ca34611-9f97-4700-a5d3-e1402b65f41b",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "Z. Yuan, X. Zhou, and T. Yang, 'Hetero-convlstm: A deep learning approach to traffic accident prediction on heterogeneous spatio-temporal data,' in Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , 2018, pp. 984-992.",
      "image_ids": []
    },
    {
      "block_id": "ea370ccb-1b60-46e3-a998-4e296ec55e34",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "S. Wang, J. Zhang, J. Li, H. Miao, and J. Cao, 'Traffic accident risk prediction via multi-view multi-task spatio-temporal networks,' IEEE Transactions on Knowledge and Data Engineering , 2021.",
      "image_ids": []
    },
    {
      "block_id": "f79b9cee-e434-4f22-a70d-d725e52ad602",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly et al. , 'An image is worth 16x16 words: Transformers for image recognition at scale,' arXiv preprint arXiv:2010.11929 , 2020.",
      "image_ids": []
    },
    {
      "block_id": "55ef998d-2881-4f37-ad9e-cd0557dd2ef6",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "B. Wu, C. Xu, X. Dai, A. Wan, P. Zhang, Z. Yan, M. Tomizuka, J. Gonzalez, K. Keutzer, and P. Vajda, 'Visual transformers: Tokenbased image representation and processing for computer vision,' arXiv preprint arXiv:2006.03677 , 2020.",
      "image_ids": []
    },
    {
      "block_id": "f8a56c93-b06c-4904-b976-dbf9f7e83def",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, \u0141. Kaiser, and I. Polosukhin, 'Attention is all you need,' Advances in neural information processing systems , vol. 30, 2017.",
      "image_ids": []
    },
    {
      "block_id": "3652f1e6-e347-4443-935b-d7873e1f1b46",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "C. Chen, X. Fan, C. Zheng, L. Xiao, M. Cheng, and C. Wang, 'Sdcae: Stack denoising convolutional autoencoder model for accident risk prediction via traffic big data,' in 2018 Sixth International Conference on Advanced Cloud and Big Data (CBD) . IEEE, 2018, pp. 328-333.",
      "image_ids": []
    },
    {
      "block_id": "bae45e18-646d-4488-8f5a-d9f8a588f9ee",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, 'Empirical evaluation of gated recurrent neural networks on sequence modeling,' arXiv preprint arXiv:1412.3555 , 2014.",
      "image_ids": []
    },
    {
      "block_id": "fb4e9215-2eb6-4999-aebf-6949099bfc2a",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "Z. Wu, S. Pan, G. Long, J. Jiang, and C. Zhang, 'Graph wavenet for deep spatial-temporal graph modeling,' arXiv preprint arXiv:1906.00121 , 2019.",
      "image_ids": []
    },
    {
      "block_id": "68cbd1fe-dc49-469d-80fb-a0e2593f3db4",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "J. Bao, P. Liu, and S. V. Ukkusuri, 'A spatiotemporal deep learning approach for citywide short-term crash risk prediction with multi-source data,' Accident Analysis & Prevention , vol. 122, pp. 239-254, 2019.",
      "image_ids": []
    },
    {
      "block_id": "602834b5-8eaa-42e8-9161-27392a24bc0c",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Doll\u00b4 ar, 'Focal loss for dense object detection,' in Proceedings of the IEEE international conference on computer vision , 2017, pp. 2980-2988.",
      "image_ids": []
    },
    {
      "block_id": "5bfc1d61-61ca-4360-b2e7-8d8dc53e6eb7",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "element_type": "list",
      "content": "C. Ma, Y. Zhang, Q. Wang, and X. Liu, 'Point-of-interest recommendation: Exploiting self-attentive autoencoders with neighbor-aware influence,' in Proceedings of the 27th ACM International Conference on Information and Knowledge Management , 2018, pp. 697-706.",
      "image_ids": []
    }
  ],
  "chunks": [
    {
      "chunk_id": "e37a162b-7f8d-455f-acec-02e4b172d231",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "block_ids": [
        "692f2a12-8cb7-4db3-b686-72c98d3b02c4",
        "08bd2ce5-9039-4d43-bf2d-79174fb534b6",
        "41626654-44ed-4be0-b93f-8bb40f6e375d",
        "663bd57c-810f-4306-95e0-d03324b83223",
        "5a606e2c-f730-4138-b87d-ce7ddf34b341",
        "00da8d34-407d-482c-b176-591e3b6bd858",
        "29c3d22a-5661-469a-9d87-a6fd6e09042a"
      ],
      "content": "1 st Khaled Saleh\n\nFaculty of Engineering and IT University of Technology Sydney\n\nSydney, Australia khaled.aboufarw@uts.edu.au\n\n2 rd Artur Grigorev\n\nFaculty of Engineering and IT University of Technology Sydney\n\nSydney, Australia\n\nORCID: 0000-0001-6875-3568",
      "image_ids": []
    },
    {
      "chunk_id": "9b9276a9-4bd5-485a-b38a-5251f3e71dec",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "block_ids": [
        "2d8dcf50-e799-442e-b7b2-3ef1a2ebb1e9"
      ],
      "content": "Abstract -Recently, the problem of traffic accident risk forecasting has been getting the attention of the intelligent transportation systems community due to its significant impact on traffic clearance. This problem is commonly tackled in the literature by using data-driven approaches that model the spatial and temporal incident impact, since they were shown to be crucial for the traffic accident risk forecasting problem. To achieve this, most approaches build different architectures to",
      "image_ids": []
    },
    {
      "chunk_id": "3af00648-5455-4f2f-866b-90569e793896",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "block_ids": [
        "2d8dcf50-e799-442e-b7b2-3ef1a2ebb1e9"
      ],
      "content": "risk forecasting problem. To achieve this, most approaches build different architectures to capture the spatio-temporal correlations features, making them inefficient for large traffic accident datasets. Thus, in this work, we are proposing a novel unified framework, namely a contextual vision transformer, that can be trained in an end-to-end approach which can effectively reason about the spatial and temporal aspects of the problem while providing accurate traffic accident risk predictions. We",
      "image_ids": []
    },
    {
      "chunk_id": "b219eb5a-8077-46a7-bd43-a03b3dece63d",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "block_ids": [
        "2d8dcf50-e799-442e-b7b2-3ef1a2ebb1e9"
      ],
      "content": "and temporal aspects of the problem while providing accurate traffic accident risk predictions. We evaluate and compare the performance of our proposed methodology against baseline approaches from the literature across two large-scale traffic accident datasets from two different geographical locations. The results have shown a significant improvement with roughly 2% in RMSE score in comparison to previous state-of-art works (SoTA) in the literature. Moreover, our proposed approach has",
      "image_ids": []
    },
    {
      "chunk_id": "549bfd15-b90a-49d1-913b-eabe65734a84",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "block_ids": [
        "2d8dcf50-e799-442e-b7b2-3ef1a2ebb1e9"
      ],
      "content": "to previous state-of-art works (SoTA) in the literature. Moreover, our proposed approach has outperformed the SoTA technique over the two datasets while only requiring 23x fewer computational requirements.",
      "image_ids": []
    },
    {
      "chunk_id": "7f2046b1-9fb5-44da-9ca3-b0e57860b326",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "601a56e8-4c5c-457d-be7c-f5a66c3a4e8f",
      "block_ids": [
        "51c50b1c-9888-4266-9198-5c8e0bf772ba"
      ],
      "content": "Index Terms -traffic accident risk; risk prediction; vision transformers; deep learning",
      "image_ids": []
    },
    {
      "chunk_id": "10befbf0-28ad-463d-9a3c-679fdebec596",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "45d24534-00ef-482c-a5cb-bbdab0858761"
      ],
      "content": "Traffic accidents represent a major concern for cities around the world due to a significant economical and health impact to their populations. The number of vehicles has been substantially increasing during the past decades, especially in developing countries, which lead to an increase in the number of traffic accidents [1]. The National Highway Traffic Safety Administration (NHTSA) reports more than 5 million traffic accidents happening in the United States each year [2]. The World Health",
      "image_ids": [
        "dc5bdc1c-c8f8-45e6-9129-b8b9c2590ec5"
      ]
    },
    {
      "chunk_id": "6cfafd93-1c0a-46fd-9d2f-43a847b97fbd",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "45d24534-00ef-482c-a5cb-bbdab0858761"
      ],
      "content": "than 5 million traffic accidents happening in the United States each year [2]. The World Health Organization also reported 1.35 million fatalities happening worldwide which resulted from traffic accidents in 2016 [3].",
      "image_ids": [
        "dc5bdc1c-c8f8-45e6-9129-b8b9c2590ec5"
      ]
    },
    {
      "chunk_id": "5bde0b7e-1b2d-449e-a966-34b74371a58c",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "d7acbf75-7004-4776-afeb-056c31c33465"
      ],
      "content": "In the past years, traffic accident research has seen an increased use of computational methods. Different problems were addressed, including: 1) traffic accident duration prediction methods, [4] 2) accident detection [5], 3) estimation of severity, and more recently, a development of spatialtemporal modelling methods have allowed to perform accident risk prediction using high-dimensional spatial, semantic and temporal data sets [6]. The use of such methods has enhanced the automated analysis",
      "image_ids": [
        "dc5bdc1c-c8f8-45e6-9129-b8b9c2590ec5"
      ]
    },
    {
      "chunk_id": "ade855a0-9977-4c6a-ab20-893a559f7bb4",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "d7acbf75-7004-4776-afeb-056c31c33465"
      ],
      "content": "semantic and temporal data sets [6]. The use of such methods has enhanced the automated analysis of traffic data together with",
      "image_ids": [
        "dc5bdc1c-c8f8-45e6-9129-b8b9c2590ec5"
      ]
    },
    {
      "chunk_id": "4982ab63-f6eb-494e-a114-0a5035542a51",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "d1aa96cc-bed5-4c69-88a9-529e326bd2ba",
        "7b75fef3-a6af-452c-b41a-25241c9c4bbe",
        "9928c3c7-26ec-4736-8fd5-7a84de2b3cd7",
        "908f4902-988c-4f28-a27a-c82655144dc1",
        "bce66f1b-4745-4fbe-9cf6-ca39616a7675",
        "02299c8e-6d8b-4340-9071-dff67b4d9f59"
      ],
      "content": "3 nd Adriana-Simona Mih\u02d8 ait \u00b8\u02d8 a\n\nFaculty of Engineering and IT University of Technology Sydney\n\nSydney, Australia\n\nORCID: 0000-0001-7670-5777\n\n[IMAGE: ]\n\nFigure 1. City grid representation for our study.",
      "image_ids": [
        "dc5bdc1c-c8f8-45e6-9129-b8b9c2590ec5"
      ]
    },
    {
      "chunk_id": "af7f2fa5-d671-4e68-b3cb-2f53e05fe8a1",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "1530fa72-d525-4fbe-ad36-79d58450574e"
      ],
      "content": "the increasing number of publicly available data sets. Traffic accident risk prediction allows to: 1) detect high-risk areas within a traffic network, which may facilitate the decisionmaking inside traffic management authorities, 2) to allocate resources and assess the road design to reduce the number of accidents in the future, 3) to predict timely high-risk situations on the road and 4) to allow an implementation of risk-reducing traffic management strategies.",
      "image_ids": [
        "dc5bdc1c-c8f8-45e6-9129-b8b9c2590ec5"
      ]
    },
    {
      "chunk_id": "fb861b0a-c7ae-410e-b3da-dd0019116a30",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "73120c31-de73-4183-ac19-509ec98559fc"
      ],
      "content": "In the literature, the traffic accident risk forecasting problem is commonly formulated as a time-series forecasting task, where given past historical traffic accidents data for a certain city/region, along with an optional contextual information about those accidents, the objective is to forecast/predict the future traffic accident risk for that city/region. Since the nature of the traffic accident risk problem implicitly involves two types of modelling, e.g. the spatial approach (working on",
      "image_ids": [
        "dc5bdc1c-c8f8-45e6-9129-b8b9c2590ec5"
      ]
    },
    {
      "chunk_id": "24464e37-161d-4360-bca4-5fbddb0da769",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "73120c31-de73-4183-ac19-509ec98559fc"
      ],
      "content": "risk problem implicitly involves two types of modelling, e.g. the spatial approach (working on the affected geographic region) and the temporal approach (applied over a period of time), thus this problem is often tackled using at least two different types of model architectures.",
      "image_ids": [
        "dc5bdc1c-c8f8-45e6-9129-b8b9c2590ec5"
      ]
    },
    {
      "chunk_id": "f0a22805-80aa-4ace-adb5-6cea67d3451d",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "e37e6310-0073-4939-8c60-1339ffadec74"
      ],
      "content": "One of the first works on traffic accident risk prediction using Deep Learning has been performed with human mobility data using a Stack Denoise Autoencoder (SDAE) on the Japan traffic network [7], but traffic flow and time-related matters (including periodicity) were not considered. Another research [8] relied on the LSTM network to improve the risk prediction in comparison to SAE by considering in addition the air quality, traffic flow and the weather data, represented as short-term and",
      "image_ids": [
        "dc5bdc1c-c8f8-45e6-9129-b8b9c2590ec5"
      ]
    },
    {
      "chunk_id": "10ce04cc-8841-4bf9-b13e-15ff24f041fa",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "e37e6310-0073-4939-8c60-1339ffadec74"
      ],
      "content": "in addition the air quality, traffic flow and the weather data, represented as short-term and periodic components. [9] proposed also a Coarse and Fine grained prediction on the target accident risk map. RiskOracle [10] relied on Graph-Convolution network, utilizing hierarchical coarse-to-fine modelling and proposing minute-level predictions in comparison to day-level [11] and",
      "image_ids": [
        "dc5bdc1c-c8f8-45e6-9129-b8b9c2590ec5"
      ]
    },
    {
      "chunk_id": "f824ca17-e838-4817-869a-1fbaee1269b7",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "cf9b0bd2-73c6-4d45-90fb-edbcf4676dac",
        "90d9b838-054d-4172-9da5-228231fbcde4"
      ],
      "content": "[IMAGE: ]\n\nFigure 2. The building blocks of our proposed C-ViT model.",
      "image_ids": [
        "390c77ac-0d33-4384-978c-d223d7e6dc0f"
      ]
    },
    {
      "chunk_id": "154883d2-7854-4b15-9fc9-f41ba8f30dba",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "266cca58-264a-4787-818f-10702131fd79"
      ],
      "content": "hour-level [7]. In [11] authors have constructed over the ConvLSTM by highlighting the spatial heterogeneity problem and proposing an ensemble of region-specific ConvLSTM models (Hetero-ConvLSTM); they considered weather, the environment and the road condition in Iowa, US for over 8 years of observations, but POIs were not considered. Semantic features, coarse and fine grained risk maps were considered in [12], where also Graph-convolution neural networks and attention-based LSTMs were used. A",
      "image_ids": [
        "390c77ac-0d33-4384-978c-d223d7e6dc0f"
      ]
    },
    {
      "chunk_id": "31a371e8-ff47-498c-ba2b-11475e32d0c2",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "266cca58-264a-4787-818f-10702131fd79"
      ],
      "content": "in [12], where also Graph-convolution neural networks and attention-based LSTMs were used. A more recent work in [6] represents the State-of-Art (SoTA) in the field of accident risk prediction, where the authors propose a weighted loss function to address the zero-inflated issue (increase in the number of zero-risk grid cells due to the increase in the granularity of predictions) and making ensemble of models by processing semantic and geo features. So far, risk accident prediction relied",
      "image_ids": [
        "390c77ac-0d33-4384-978c-d223d7e6dc0f"
      ]
    },
    {
      "chunk_id": "d112f9f2-ed83-42ef-990d-964e21d73b2b",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "266cca58-264a-4787-818f-10702131fd79"
      ],
      "content": "ensemble of models by processing semantic and geo features. So far, risk accident prediction relied mostly upon graph-based methods and spatial-temporal modelling. While this approach worked for limited case study applications, we highly believe that in order to scale it up, this approach can benefit from using visual analysis techniques. Thus, in this work we are re-formulating the problem of traffic accident risk forecasting and we are proposing a novel approach inspired by one of the recent",
      "image_ids": [
        "390c77ac-0d33-4384-978c-d223d7e6dc0f"
      ]
    },
    {
      "chunk_id": "359f9b84-082e-44d4-8d3e-32d58888ad56",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "266cca58-264a-4787-818f-10702131fd79"
      ],
      "content": "accident risk forecasting and we are proposing a novel approach inspired by one of the recent best performing deep learning based architectures for computer vision tasks, the vision transformers [13]. In our proposed model we jointly model and take into account the spatio-temporal nature of the traffic accident risk forecasting problem as well as the influence of contextual information on it using a single unified end-to-end model.",
      "image_ids": [
        "390c77ac-0d33-4384-978c-d223d7e6dc0f"
      ]
    },
    {
      "chunk_id": "c1d7a389-a0ea-4bb5-93ba-4b87f447c31f",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "2bf41644-c6e0-4b5c-b5ec-af15be1f556e",
      "block_ids": [
        "210fc51d-1d6b-49bb-a4d7-6331c0b66717"
      ],
      "content": "In Section II, a detailed description about the proposed methodology will be presented. Then, in Section III, we will introduce the datasets we utilised for training and evaluating the performance of our approach, the experiments setup and the baseline approaches from the literature we compared our approach against. Finally, in Section IV, we conclude our paper.",
      "image_ids": [
        "390c77ac-0d33-4384-978c-d223d7e6dc0f"
      ]
    },
    {
      "chunk_id": "84c6353d-3814-4c78-81ce-7aa542e26049",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "6dbd69d4-64cf-4e38-a9cb-24cc5259d1f4",
      "block_ids": [
        "3e0a563f-5296-40b6-aea5-2a343096a051"
      ],
      "content": "In this section, we will first start with definitions and the problem formulation for the traffic accident risk forecasting task. Then, we will present and discuss the details of our proposed contextual vision transformer (C-ViT) model (as shown in Fig. 2).",
      "image_ids": []
    },
    {
      "chunk_id": "9efc089f-f47d-4b94-a2ab-d8e25e703d4f",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "b815b072-5c71-492e-a19e-3b48c618eafe",
      "block_ids": [
        "7ce59324-f296-4a09-9815-b7faa786c178"
      ],
      "content": "Grid Representation: Given a city area bounded by certain latitude and longitude coordinates, we partition it into a grid form with I rows \u00d7 J columns (as shown in Fig. 1), where each cell share the same size.",
      "image_ids": []
    },
    {
      "chunk_id": "fff5d427-75b1-4fd9-a2d1-f767a012ff02",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "b815b072-5c71-492e-a19e-3b48c618eafe",
      "block_ids": [
        "50c8f171-1a65-4ebd-b7ff-a969647aee91"
      ],
      "content": "Traffic Accident Risk: At any given time t , the traffic accident risk Y i t for a grid cell i is defined by the summation of the different types of traffic accidents occurred at that grid cell. Similar to [6], we have three types of traffic accidents and each one has a corresponding value, namely a minor accident has a value of 1, an injured accident a value of 2 and a fatal accident has a value of 3. For instance, if a grid cell incurred three fatal accidents and two minor accidents, the",
      "image_ids": []
    },
    {
      "chunk_id": "3dbee19c-fad1-41ae-a937-b3e8e1282624",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "b815b072-5c71-492e-a19e-3b48c618eafe",
      "block_ids": [
        "50c8f171-1a65-4ebd-b7ff-a969647aee91"
      ],
      "content": "of 3. For instance, if a grid cell incurred three fatal accidents and two minor accidents, the traffic accident risk for it then would be 11.",
      "image_ids": []
    },
    {
      "chunk_id": "1f25bc89-27a2-48fa-b148-e132d1161ec5",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "6270cb10-b1be-46f2-80bd-afb2981f4d20",
      "block_ids": [
        "4cdd1fda-2502-4b85-b854-b964a8b7640a"
      ],
      "content": "In our formulation of the traffic accident prediction problem, we re-cast it as an image regression task instead of the traditional formulation as a time-series prediction task. This new formulation enables us to natively model the spatiotemporal nature of the traffic accident prediction problem in an end-to-end fashion without the need to have a combination of more than one architecture to address it. To that end, given historical observations in the form of a traffic accident risk map Z 1: T ,",
      "image_ids": []
    },
    {
      "chunk_id": "b359b5e1-c5a8-41ad-a9cb-01ead8b35321",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "section_id": "6270cb10-b1be-46f2-80bd-afb2981f4d20",
      "block_ids": [
        "4cdd1fda-2502-4b85-b854-b964a8b7640a"
      ],
      "content": "it. To that end, given historical observations in the form of a traffic accident risk map Z 1: T , where Z \u2208 R I \u00d7 J over time period [ 1 : T ] , we represent these observations as an image X with a resolution of I \u00d7 J and its number of channels to be T . Then we feed it to our proposed C-ViT model that fuse it together with the historical contextual information C 1: T to predict/regress the future accident risk map in the next hour \u02c6 Y T + 1, where Y \u2208 R I \u00d7 J .",
      "image_ids": []
    },
    {
      "chunk_id": "a4770f1b-7840-43f7-a8ac-40cb567403e9",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "b6afc435-8847-4985-b247-f7a7992e0060"
      ],
      "content": "Given the aforementioned formulation, we compile the traffic accident risk maps Z 1: T as a unified single image with size T \u00d7 I \u00d7 J , where T is the number of channels, I is the image's height and J is the image's width, which we pass as an input to our proposed novel C-ViT model. Our C-ViT model's architecture is inspired by the recently introduced vision transformer network [13] that has been achieving competitive results to the convolutional neural network (ConvNet) architecture for image",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "chunk_id": "4b7745ce-af53-4ce2-b1d8-f687bb25546d",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "b6afc435-8847-4985-b247-f7a7992e0060"
      ],
      "content": "achieving competitive results to the convolutional neural network (ConvNet) architecture for image classification tasks [13], [14]. The main building blocks of our C-ViT model are three components, namely the historical traffic accident risk map encoding stage, the historical contextual information encoding stage and the transformer encoder stage. In the following we will analyse deeper each component.",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "chunk_id": "40788dec-b04c-4be3-8136-5dc735dd1102",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "174bde62-d0be-4c17-825f-251a91ec9936",
        "b5534d2d-e527-486f-bf16-19e9c2f70116"
      ],
      "content": "[IMAGE: ]\n\nFigure 3. Description of the first stage of the historical risk Map encoding. Given a unified single image X , it is then divided into equally-sized image patches that are passed individually to the linear patch embedding layer.",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "chunk_id": "2638299b-bc4c-40ec-a5e8-6018cfd96086",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "54439462-d117-4a8c-b578-7853fef2ed33"
      ],
      "content": "Historical Risk Map Encoding: Given the historical risk maps as a unified single image X with size T \u00d7 I \u00d7 J , we first encode it into a representation that could be easily digested and learned using our transformer encoder. As it was shown in [15], transformer encoders can work better with input data as a sequence of tokens. Thus, we divide the unified single image into a sequence of equally sub-images Xp which we refer to it as an image patch sequence. We can think of the image patches as a",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "chunk_id": "56ac52c9-f382-450d-9e76-a006ce23b3f2",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "54439462-d117-4a8c-b578-7853fef2ed33"
      ],
      "content": "Xp which we refer to it as an image patch sequence. We can think of the image patches as a sub-spatial regions of a number of cells within the city's grid representation that we defined in Section II-B. The rationale behind this patching process is derived by the assumption that grid cells that are spatially closer to each others will have some geographical and spatial correlations that could potentially be exploited by our model for conducting a better traffic accident risk forecasting.",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "chunk_id": "7f7e0f72-619e-4c56-84a6-005f3a221043",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "2e076b9f-bc98-4bbd-86c2-a3135d30f596"
      ],
      "content": "Here Xp has a size of N \u00d7 T \u00d7 P \u00d7 P , where P is the height/width of the image patch and N is the total number of sequences of image patches, which is defined by N = IJ / P 2 . The operation of dividing the unified single image into a sequence of image patches Xp can be shown in Fig. 3. The image patches sequence are then individually passed through a linear embedding layer which is essentially a learn-able linear projection operation in order to get a sequence of trainable flattened image",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "chunk_id": "509f01f8-7ccf-4c2f-850b-13d9fb316d5f",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "2e076b9f-bc98-4bbd-86c2-a3135d30f596"
      ],
      "content": "a learn-able linear projection operation in order to get a sequence of trainable flattened image patches of size D , which we refer to as patch embeddings. Additionally, similar to [13], we have an extra learnable embedding token appended before the sequence of patch embeddings to be passed to the transformer encoder and we refer to this embedding as a 'regression token'. The regression token embedding acts as an image representation which its output is transformed inside the transformer",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "chunk_id": "d1a83bcb-6200-42c9-9ae7-67555335ad28",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "2e076b9f-bc98-4bbd-86c2-a3135d30f596"
      ],
      "content": "embedding acts as an image representation which its output is transformed inside the transformer encoder into the predicted accident risk map \u02c6 Y T + 1.",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "chunk_id": "e4f80863-756e-4449-8bc1-95ed65de9919",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "9fa94617-8749-4b8f-835a-958bebd9569c"
      ],
      "content": "Since the transformer encoder does not have the notion of order in its input sequence tokens, an additional position embeddings are added to each patch embedding. There are a number of pathways to define position embedding, and in our current model we follow the formulation introduced in [15]. In this formulation, the position encoding PE vector is defined by using a wide spectrum of frequencies of sine/cosine functions as follows:",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "chunk_id": "6f231b77-ecd9-4e00-901e-d98c2c12df81",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "3d750bab-8d41-434e-ac40-225388c64da7"
      ],
      "content": "where a represents the position, and k is the dimension. From the above formulation, once can conclude that for each dimension k of PE vector, it has a corresponding sinusoid that spans a frequency range from 2 p to 10000 \u00b7 2 p . In other words, this will allow the model to be mindful of the order in the sequential patch embedding by using unique relative positions. The dimension of the PE vector is similar to the linear patch embedding layer's dimension which is D .",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "chunk_id": "f9e75941-bb6b-40c9-9ad4-f6d5133bbcf1",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "fb57e1eb-e426-476e-ac1e-b0f3dc68ede1"
      ],
      "content": "Historical Contextual Information Encoding As discussed in Section II-B, besides the historical accident risk maps, our C-ViT model takes into account also the historical contextual information C 1: T for the city grid representation. In our model and similar to [6], we took into account the following contextual features: 1) the time period of the day, 2) the day of the week, 3) whether the day is a holiday or not, 4) the weather condition (clear, cloud,..etc), 5) the weather temperature, and",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "chunk_id": "9a6d871f-3ed7-4e8a-a67a-2bb08c58c82f",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "fb57e1eb-e426-476e-ac1e-b0f3dc68ede1"
      ],
      "content": "is a holiday or not, 4) the weather condition (clear, cloud,..etc), 5) the weather temperature, and 6) traffic condition (inflow and outflow). Given those contextual features, we encode them via a learnable linear embedding layer of dimension D , whose output is fused together with the output from the transformer encoder via a concatenation operation.",
      "image_ids": [
        "497c0dfc-d1d8-4104-8eb1-54e1bdc887db"
      ]
    },
    {
      "chunk_id": "274398f2-aa5f-4dc1-93df-341f6bc8b9ed",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "a0eb8bbf-059f-40d8-80f0-8d1c131737ca"
      ],
      "content": "Transformer Encoder The main building block of our transformer encoder is the multi-head self-attention module [15]. In total we have six layers inside our transformer encoder. Internally, each layer is composed of a both selfattention head and feed-forward fully connected sub-layers. Additionally, each sub-layer is followed by two residual connections and a normalisation operation. The multi-head self-attention, or the multi-scaled dot-product attention, works based on the mapping between the",
      "image_ids": []
    },
    {
      "chunk_id": "aa62c90c-09a9-46f6-a145-5835de6b501a",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "a0eb8bbf-059f-40d8-80f0-8d1c131737ca"
      ],
      "content": "self-attention, or the multi-scaled dot-product attention, works based on the mapping between the so-called 'query' vectors and the pair (key, value) vectors. The dimension of the query and key vectors is dk , where the values vector dimension is dv . The attention operation itself is computed by taking the dot-product between the query and the key vectors divided by the square root of dk before finally passing them to the softmax function to get their weights by their values. Since the scaled",
      "image_ids": []
    },
    {
      "chunk_id": "73d4a3ea-03c2-400d-8dd0-e498717fbe80",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "deb6a8c4-5608-4f0c-adcf-b42cf3e55336",
      "block_ids": [
        "a0eb8bbf-059f-40d8-80f0-8d1c131737ca"
      ],
      "content": "finally passing them to the softmax function to get their weights by their values. Since the scaled dot-product attention operation is done multiple times, the queries, keys and values vectors are extended into matrices Q , K , V respectively. The following formula is the description of how the scaled dot-product attention operation is calculated:",
      "image_ids": []
    },
    {
      "chunk_id": "8526aaa7-aec3-4fa5-9d9e-1b1850bc23dc",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "98c0ae99-ae54-4838-9662-59de83afaa45",
      "block_ids": [
        "9862422d-f3bf-4cb0-9dda-9bfcae20dcc5"
      ],
      "content": "In this section, we first present the datasets we utilised for training and evaluating the performance of our proposed approach. Then, we provide the details of the setup for our experiments, the evaluation metrics and the compared baseline approaches from the the literature. Finally, the quantitative and qualitative results of our proposed approach on real-life datasets are evaluated and discussed.",
      "image_ids": []
    },
    {
      "chunk_id": "2dc2c313-462d-4c07-9536-fac99f15d04a",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "9e35d1e1-c886-41d4-8cdc-a876cbb44b80",
      "block_ids": [
        "fb9f1f43-1c71-40b0-9d90-febeb6f27066"
      ],
      "content": "In this study we use two publicly available real datasets for the traffic accident risk forecasting problem, namely NYC 1 and Chicago 2 . As it can be seen from Table I, both datasets have historical traffic accidents and historical taxi trips. The historical traffic accident data contains: time, date, location (latitude and longitude), the number of causalities, the weather condition (clear, cloudy, rainy, snowy or mist), the temperature and the road segment data (i.e. road length, width and",
      "image_ids": []
    },
    {
      "chunk_id": "50094f3a-e5d5-4bac-a03f-49ae7b2de77b",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "9e35d1e1-c886-41d4-8cdc-a876cbb44b80",
      "block_ids": [
        "fb9f1f43-1c71-40b0-9d90-febeb6f27066"
      ],
      "content": "rainy, snowy or mist), the temperature and the road segment data (i.e. road length, width and type). The NYC dataset has an additional Point of interest (POI) data regarding locations (i.e. residence, school, culture facility, recreation, social service, transportation and commercial). The historical taxi trips include the location and times of pick-up and drop-offs and this data is used to calculate the inflow/outflow of the traffic condition in each area.",
      "image_ids": []
    },
    {
      "chunk_id": "7ae8160f-d20e-4bf5-8646-33317c0eb3e4",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "9e35d1e1-c886-41d4-8cdc-a876cbb44b80",
      "block_ids": [
        "a8444eb5-67e1-4eef-a959-42ab8257af0c",
        "cf3b361b-5c37-4477-9204-073f8bdd2b4c",
        "898edb2f-182c-4cdd-b388-8cd9c673d6be"
      ],
      "content": "1 https://opendata.cityofnewyork.us/\n\n2 https://data.cityofchicago.org/\n\nTable I DATASETS STATISTICS",
      "image_ids": []
    },
    {
      "chunk_id": "abed37af-691e-4247-afbd-bb45bad48e3d",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "block_ids": [
        "77d8fdf0-4e23-46a9-848e-04e65d00bcdb"
      ],
      "content": "Before we train and evaluate our proposed C-ViT model, we first pre-process the two datasets. The first pre-processing stage was to perform a grid representation by dividing each city map of the two datasets (i.e. NYC and Chicago) into equally-sized grid cells each with a dimension of (2 KM \u00d7 2 KM ). Secondly, similar to [6], we group all the accidents that happened in each grid cell based on their location over the reported duration time for each dataset (for each grid cells with no road",
      "image_ids": []
    },
    {
      "chunk_id": "4cd7e283-c292-4329-bb09-dde8276e99d0",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "block_ids": [
        "77d8fdf0-4e23-46a9-848e-04e65d00bcdb"
      ],
      "content": "their location over the reported duration time for each dataset (for each grid cells with no road segments/accidents, we set its traffic accident risk to zero). Thirdly, we split the data-sets into training, validation and testing. The strategy we followed for the splitting is similar to [6], where we use 60% for training, 20% for validation and 20% for testing while making sure that there is no overlapping accidents based on time (i.e. no accident happened in specific grid cell on specific",
      "image_ids": []
    },
    {
      "chunk_id": "1e370814-ca61-4dba-ae5e-a4f53676693f",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "block_ids": [
        "77d8fdf0-4e23-46a9-848e-04e65d00bcdb"
      ],
      "content": "no overlapping accidents based on time (i.e. no accident happened in specific grid cell on specific time is shared between the three data splits). It is worth noting that the traffic accidents periodicity according to the two datasets was set to 1 hour. Finally, each data split is standardised by a mean and standard deviation normalisation so that it could help in accelerating the training process.",
      "image_ids": []
    },
    {
      "chunk_id": "671c7eaa-9ecc-49b4-afef-a998e0c78f22",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "block_ids": [
        "b7bff769-6d71-4c82-b1be-a97987a13735"
      ],
      "content": "Regarding the implementation details of our C-ViT model, the size of the historical traffic risk maps X was set to 7 \u00d7 20 \u00d7 20 which corresponds to a total 7 historical traffic accident risks across the city grid with I rows \u00d7 J columns of size 20. Here we chose 7 historical accident risks specifically to conform with the work done in the literature [6], [16] for a fair comparison provided later in the paper. For each grid cell, the 7 historical accident risks comes from the most recent",
      "image_ids": []
    },
    {
      "chunk_id": "133cc390-507f-4764-88b3-d55d950f9ab3",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "block_ids": [
        "b7bff769-6d71-4c82-b1be-a97987a13735"
      ],
      "content": "later in the paper. For each grid cell, the 7 historical accident risks comes from the most recent accident risks in past 3 hours in addition to the past accident risks in the last 4 weeks. The prediction horizon for the traffic accident risk was set to 1 (i.e next hour) similar to [6], [16]. The hyper-parameters for our C-ViT model itself were set according to the model performance on the validation split. To that end, the D dimension for the linear patch embedding, the position embedding",
      "image_ids": []
    },
    {
      "chunk_id": "b45196e9-cba9-49bf-8687-8798f095ebc4",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 4,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "block_ids": [
        "b7bff769-6d71-4c82-b1be-a97987a13735"
      ],
      "content": "split. To that end, the D dimension for the linear patch embedding, the position embedding layer and the linear embedding layer of the historical contextual encoder was set to 64. The resolution of input patches P to the patch embedding layer was set to 5. The number of self-attention heads were set to 8 and the final output fully connected layer of our C-ViT model was set to 128. Since we formulated the traffic accident risk prediction",
      "image_ids": []
    },
    {
      "chunk_id": "85e827ea-277f-4f44-9bb9-9f1f4883bac8",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "block_ids": [
        "cd817528-b256-4041-a6b8-4eccf7330acd"
      ],
      "content": "Table II PERFORMANCE EVALUATION OF OUR C-VIT MODEL AGAINST A NUMBER OF BASELINE APPROACHES FROM THE LITERATURE OVER THE NYC AND CHICAGO DATASETS.",
      "image_ids": []
    },
    {
      "chunk_id": "4c8c69b6-e0c6-4661-a196-71500133f790",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "block_ids": [
        "0b2ec380-e00e-4cda-af4c-08b58c9c72e3"
      ],
      "content": "task as an image regression task, we have therefore optimised our C-ViT model during the training phase using a weighted mean-squared error (MSE) loss function. The reason for using the weighted MSE loss function instead of using the standard MSE loss function, is to try to combat the unbalanced nature of the traffic risk prediction problem, also known as the zeroinflated problem [19]. The procedure for weighting our loss function is motivated by the focal loss introduced in [20], where we",
      "image_ids": []
    },
    {
      "chunk_id": "5e2d5412-ac00-43bd-8803-957cb077015d",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "e4c6d421-f9ef-4177-acfe-913ad81143cc",
      "block_ids": [
        "0b2ec380-e00e-4cda-af4c-08b58c9c72e3"
      ],
      "content": "for weighting our loss function is motivated by the focal loss introduced in [20], where we holistically divided the total training samples into four distinctive classes based on their traffic accident risk values. Those risk values are (0, 1, 2, \u2265 3). Similar to [6], the loss function weights were set to 0.05, 0.2, 0.25 and 0.5 respectively. In total, we have trained our C-ViT model for 200 epochs using the Adam optimiser with a learning rate of 0.003 and the batch size was set to 32.",
      "image_ids": []
    },
    {
      "chunk_id": "2c0f097a-7cd0-464c-be66-3d9e9902eb10",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "e3c10367-4b92-4f36-a112-cc1ea107ac8f",
      "block_ids": [
        "ab44bdc4-7aa6-4f8d-890f-c12e782a3dd7"
      ],
      "content": "In order to evaluate the performance of our trained C-ViT model, we utilised the three commonly used metrics for the traffic accident risk prediction task [6], [21], namely root mean squared error (RMSE), Recall and mean average precision (MAP). The three evaluation metrics are calculated as follows:",
      "image_ids": []
    },
    {
      "chunk_id": "1e0e5a96-1112-4079-bb8e-bedefd642d00",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "e3c10367-4b92-4f36-a112-cc1ea107ac8f",
      "block_ids": [
        "57fa3b57-4752-4981-9049-7c63cfc26769"
      ],
      "content": "where N is the total number of samples to be evaluated, Yn , \u02c6 Yn are the ground truth and the predicted risk values for all grid cells of sample n respectively. An corresponds to the set of grid cells of sample n that have an actual/true traffic accident risk values. Hn corresponds to the set of grid cells within An with the highest traffic accident risk values. On the other hand, PR ( j ) corresponds to the precision of the grid cells starting at 1 and ending at grid cell j . Similarly, REC (",
      "image_ids": []
    },
    {
      "chunk_id": "ee1dd97a-f3dc-4925-afbb-dba4886380b1",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "e3c10367-4b92-4f36-a112-cc1ea107ac8f",
      "block_ids": [
        "57fa3b57-4752-4981-9049-7c63cfc26769"
      ],
      "content": "to the precision of the grid cells starting at 1 and ending at grid cell j . Similarly, REC ( j ) corresponds to the recall value for grid cell j which is set to 1 in case there was a traffic accident risk at it and set to 0 otherwise.",
      "image_ids": []
    },
    {
      "chunk_id": "6159e9d7-9311-4d53-a860-8a64cd93201a",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "e3c10367-4b92-4f36-a112-cc1ea107ac8f",
      "block_ids": [
        "652236eb-c94f-4d88-a5c8-ec3c59db114a"
      ],
      "content": "Based on the definition of these three evaluation metrics, we can deduce that the lower the score of RMSE is, the better is the quality of prediction coming out of the model. On the other hand, the higher the recall and MAP scores are, the better is the accuracy of the model.",
      "image_ids": []
    },
    {
      "chunk_id": "7136094d-496d-4816-b5c0-f03184c17e72",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "7ba46241-369f-40e0-9417-4e8467f7042f",
      "block_ids": [
        "a5f232a4-fd26-48fb-a6d9-8c86970d759f",
        "fb8f4982-735d-47d7-b7df-a935e905e24d"
      ],
      "content": "We have compared the performance of our proposed C-ViT model to 5 different baseline approaches from the literature and in the following we will briefly describe each approach:\n\nRNN-GRU [17]: This model is based on one variant of deep recurrent neural networks (RNN), the gated recurrent unit (GRU) model. This model casts the traffic accident risk forecasting problem as a time-series prediction problem and tries to model the temporal dependency among historical traffic accidents risk.",
      "image_ids": []
    },
    {
      "chunk_id": "be590dfc-be3d-4df9-befb-08221aa7091a",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "7ba46241-369f-40e0-9417-4e8467f7042f",
      "block_ids": [
        "0bbcee85-dcd2-47d4-be6d-fa73fe919a56"
      ],
      "content": "SDCAE [16]: This model is based on the stacked denoised convolution auto-encoder architecture, which focuses mainly on capturing/modelling the spatial features between different cells within a city grid area for a better prediction of the traffic accident risk.",
      "image_ids": []
    },
    {
      "chunk_id": "5291be1b-ab0d-4ac7-9d9c-3b388fca2e16",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "7ba46241-369f-40e0-9417-4e8467f7042f",
      "block_ids": [
        "751fc987-8358-4015-81ad-5b63b8522058"
      ],
      "content": "H-ConvLSTM [11]: As the name implies, this model combines both deep convolution layers with RNN-based LSTM layers to extract the spatio-temporal features of the traffic accident risk problem by having a sliding window over the city's grid cells; this allows to have sub-regions that could potentially capture the heterogeneity among the different types of spatial regions.",
      "image_ids": []
    },
    {
      "chunk_id": "56eecc6d-66d5-4a91-b220-8055cc04279b",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "7ba46241-369f-40e0-9417-4e8467f7042f",
      "block_ids": [
        "ad9582f0-50e4-493c-93a2-6628ad621f23"
      ],
      "content": "GCN [18]: This model is a deep learning model that relies on graph convolution neural network to represent the historical traffic accident data as a graph to capture the long-term spatio-temporal dependency among historical traffic accidents risk data.",
      "image_ids": []
    },
    {
      "chunk_id": "d5f4ec52-52d1-448a-bcae-6b86a8ddb356",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "7ba46241-369f-40e0-9417-4e8467f7042f",
      "block_ids": [
        "bacbf4fa-f92e-4253-9b3d-e68a57f8d71b"
      ],
      "content": "GSNet [6]: A recent model that learns the complex spatial-temporal correlations of traffic accidents risk by using a combination of GCN, LSTM and attention mechanism. To the best of our knowledge, GSNet is currently the SOTA method on the NYC and Chicago data-sets.",
      "image_ids": []
    },
    {
      "chunk_id": "7e3532e5-3b20-458d-8342-aeaee9edd3c3",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 5,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "block_ids": [
        "1c70b254-f3ef-42d7-8e8d-dd56d8a91ba3",
        "16171c7d-ffa2-4df0-8bbc-82e37d5ff9dc"
      ],
      "content": "In Table II, we report the results of our C-ViT model in comparison to the aforementioned baseline approaches\n\nTable III PERFORMANCE EVALUATION OF OUR C-VIT MODEL AGAINST A NUMBER OF BASELINE APPROACHES FROM THE LITERATURE OVER THE HIGH FREQUENCY TIMES OF ACCIDENTS IN THE NYC AND CHICAGO DATASETS.",
      "image_ids": []
    },
    {
      "chunk_id": "97a98cc8-ea74-4b63-8ea3-d1bc4794f3c3",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "block_ids": [
        "a716ca98-2145-49d0-a3f9-a11d2f97447b"
      ],
      "content": "from the literature over the total testing splits for both NYC and Chicago data-sets. As it can be noticed, our model has outperformed all the baseline approaches from the literature in terms of RMSE, recall and MAP scores over the two datasets. It is worth noting from the results, that those models (our C-ViT, GSNet, GCN and H-ConvLSTM) which account for the spatio-temporal property of the traffic accident risk prediction problem, are the top performing approaches on the two data-sets.",
      "image_ids": [
        "85cc7aa9-8ea4-4eb5-8c94-0e1f1b55cc07"
      ]
    },
    {
      "chunk_id": "30b8f372-f527-4c36-a451-b64827466034",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "block_ids": [
        "2b48353c-2731-4e94-ba28-79031a433e1f",
        "5dc9fd4d-598b-4a07-9af6-5038db9d57df"
      ],
      "content": "[IMAGE: ]\n\nFigure 4. Comparison between our proposed C-ViT model and GSNet [6], in terms of the number of training parameters.",
      "image_ids": [
        "85cc7aa9-8ea4-4eb5-8c94-0e1f1b55cc07"
      ]
    },
    {
      "chunk_id": "c4b6651e-cb81-4167-8ddc-5ff9ba88bf9c",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "block_ids": [
        "47e900e9-db9e-4efa-84e9-104490c30e16"
      ],
      "content": "The closest competitor baseline approach to our C-ViT model, was the GSNet, which to the best of our knowledge, was the SOTA on the two data-sets before our proposed approach. As it can be seen, our C-ViT model has improved the RMSE, recall and MAP scores in comparison to GSNet especially across the Chicago dataset by a relatively large margin. Furthermore, our C-ViT has more competitive advantage over GSNet in terms of the efficiency. As it can be shown in Fig. 4, the number of parameters",
      "image_ids": [
        "85cc7aa9-8ea4-4eb5-8c94-0e1f1b55cc07"
      ]
    },
    {
      "chunk_id": "e6857f96-917b-40e8-8409-4873234f1275",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "block_ids": [
        "47e900e9-db9e-4efa-84e9-104490c30e16"
      ],
      "content": "over GSNet in terms of the efficiency. As it can be shown in Fig. 4, the number of parameters required by our C-ViT model for training are far lower than those needed for GSNet (saving more than 23x parameters) which makes our approach more suitable for real-time deployment.",
      "image_ids": [
        "85cc7aa9-8ea4-4eb5-8c94-0e1f1b55cc07"
      ]
    },
    {
      "chunk_id": "c2013c3d-2caa-4fe5-8cbd-8405d2e967f8",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "block_ids": [
        "24637bcb-ac59-4820-b36b-355617758dc6"
      ],
      "content": "In order to further evaluate the performance of our proposed C-ViT model, in Table III we report the RMSE, recall and MAP scores of our model when compared to all the other baseline approaches over peak hours of frequent traffic accidents that resulted from the testing split of both the NYC and",
      "image_ids": [
        "85cc7aa9-8ea4-4eb5-8c94-0e1f1b55cc07"
      ]
    },
    {
      "chunk_id": "8b371ae2-683b-4be4-bb11-5232e1e7d599",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "94e84e27-1df4-458d-b9cd-2441c5ec98fe",
      "block_ids": [
        "e87fe9a0-509f-455e-bea1-e27f9226c4eb"
      ],
      "content": "Chicago data-sets. Those times of high frequency of traffic accidents are essentially during morning/evening rush hours which are within 7:00-9:00 AM and 04:00-07:00 PM. As it can be seen from the reported results, our C-ViT model continues to achieve more robust results than all other compared baseline approaches. This further prove the utility and quality of our proposed approach that it has a consistent performance across different settings.",
      "image_ids": [
        "85cc7aa9-8ea4-4eb5-8c94-0e1f1b55cc07"
      ]
    },
    {
      "chunk_id": "f8006156-fa2f-4b25-9829-2aa72a53674b",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "0e4d27c9-7f70-4d9d-8898-bb69ccdbca72",
      "block_ids": [
        "56bd1d9e-428d-4ba8-b399-6e3756064252"
      ],
      "content": "In this work, we have presented a novel approach for the task of traffic accident risk forecasting. In our approach we re-formulated the problem as an image regression problem and introduced a unique contextual vision transformer network (C-ViT) that can efficiently model the traffic accident risk forecasting task from both spatial and temporal perspectives. The proposed approach has been evaluated on two publicly available datasets for the traffic accident risk problem. Furthermore, our",
      "image_ids": []
    },
    {
      "chunk_id": "372b33fe-7efe-4e71-be9f-d456eacb77aa",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "0e4d27c9-7f70-4d9d-8898-bb69ccdbca72",
      "block_ids": [
        "56bd1d9e-428d-4ba8-b399-6e3756064252"
      ],
      "content": "on two publicly available datasets for the traffic accident risk problem. Furthermore, our proposed C-ViT model has been compared against a number of baseline approaches from the literature and it has outperformed them with a large margin while only requiring less than 23 times the number of training parameters.",
      "image_ids": []
    },
    {
      "chunk_id": "1cf11e61-7c75-4322-8d2e-452d67b05798",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "fceaa985-4c43-4311-bca8-f40dbf36f47d",
      "block_ids": [
        "48e22294-516a-4da0-9426-08152900067c"
      ],
      "content": "This research is supported by the ARC LP project LP180100114. This research is funded by iMOVE CRC and supported by the Cooperative Research Centres program, an Australian Government initiative.",
      "image_ids": []
    },
    {
      "chunk_id": "5b435db1-5407-44b0-8f0e-a8eed94330ed",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "block_ids": [
        "e216c1f3-a9e4-4769-97db-e5688c05754d",
        "18e23cb7-c35a-4144-bfa7-8f6eef517e47",
        "7c39f06f-84db-4d9c-9529-da16874aac03",
        "d710869e-83d5-4880-bc69-920c9ef74e55"
      ],
      "content": "W. H. Organization, Global status report on road safety 2015 . World Health Organization, 2015.\n\nN. H. T. S. Administration, Traffic safety facts 2013 . U.S. department of transportation, 2013.\n\nW. H. Organization et al. , 'Global status report on road safety 2018: summary,' World Health Organization, Tech. Rep., 2018.\n\nR. Li, F. C. Pereira, and M. E. Ben-Akiva, 'Overview of traffic incident duration analysis and prediction,' European transport research review , vol. 10, no. 2, pp. 1-13, 2018.",
      "image_ids": []
    },
    {
      "chunk_id": "ece34ff4-831a-4fbf-b32f-4938248b49ae",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "block_ids": [
        "618cc3ed-bc3e-4716-975c-69f333950ac0",
        "88149e8c-7c8b-4f50-b1bd-c9ad5e6db3e2"
      ],
      "content": "A. B. Parsa, H. Taghipour, S. Derrible, and A. K. Mohammadian, 'Realtime accident detection: coping with imbalanced data,' Accident Analysis & Prevention , vol. 129, pp. 202-210, 2019.\n\nB. Wang, Y. Lin, S. Guo, and H. Wan, 'Gsnet: Learning spatial-temporal correlations from geographical and semantic aspects for traffic accident risk forecasting,' in Proceedings of the AAAI Conference on Artificial Intelligence , vol. 35, no. 5, 2021, pp. 4402-4409.",
      "image_ids": []
    },
    {
      "chunk_id": "ca271edc-8aa1-4fc3-b7b2-8c9d7fd9dbb4",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "block_ids": [
        "d6312a35-0b50-4968-9900-c30d8e8e20d0",
        "b83c490a-d7f7-431c-803c-a39a072ae171"
      ],
      "content": "Q. Chen, X. Song, H. Yamada, and R. Shibasaki, 'Learning deep representation from big and heterogeneous data for traffic accident inference,' in Thirtieth AAAI conference on artificial intelligence , 2016.\n\nH. Ren, Y. Song, J. Liu, Y. Hu, and J. Lei, 'A deep learning approach to the prediction of short-term traffic accident risk,' arXiv preprint arXiv:1710.09543 , 2017.",
      "image_ids": []
    },
    {
      "chunk_id": "a90bee52-3043-48de-bc5e-29beea4c35e7",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "block_ids": [
        "407a4bf8-882e-4dfc-9526-ff83546cb23c",
        "318c433a-588e-470c-aa3b-3740724db43f"
      ],
      "content": "Z. Zhou, Y. Wang, X. Xie, L. Chen, and C. Zhu, 'Foresee urban sparse traffic accidents: A spatiotemporal multi-granularity perspective,' IEEE Transactions on Knowledge and Data Engineering , 2020.\n\nZ. Zhou, Y. Wang, X. Xie, L. Chen, and H. Liu, 'Riskoracle: a minutelevel citywide traffic accident forecasting framework,' in Proceedings of the AAAI Conference on Artificial Intelligence , vol. 34, no. 01, 2020, pp. 1258-1265.",
      "image_ids": []
    },
    {
      "chunk_id": "e4c5a8c8-9751-4acd-90f2-4f0e09841822",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "block_ids": [
        "ea370ccb-1b60-46e3-a998-4e296ec55e34",
        "2ca34611-9f97-4700-a5d3-e1402b65f41b"
      ],
      "content": "Z. Yuan, X. Zhou, and T. Yang, 'Hetero-convlstm: A deep learning approach to traffic accident prediction on heterogeneous spatio-temporal data,' in Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , 2018, pp. 984-992.\n\nS. Wang, J. Zhang, J. Li, H. Miao, and J. Cao, 'Traffic accident risk prediction via multi-view multi-task spatio-temporal networks,' IEEE Transactions on Knowledge and Data Engineering , 2021.",
      "image_ids": []
    },
    {
      "chunk_id": "7607d124-cfc5-4eef-91bb-a6e2d7022bd1",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "block_ids": [
        "f79b9cee-e434-4f22-a70d-d725e52ad602",
        "55ef998d-2881-4f37-ad9e-cd0557dd2ef6"
      ],
      "content": "A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly et al. , 'An image is worth 16x16 words: Transformers for image recognition at scale,' arXiv preprint arXiv:2010.11929 , 2020.\n\nB. Wu, C. Xu, X. Dai, A. Wan, P. Zhang, Z. Yan, M. Tomizuka, J. Gonzalez, K. Keutzer, and P. Vajda, 'Visual transformers: Tokenbased image representation and processing for computer vision,' arXiv preprint arXiv:2006.03677 , 2020.",
      "image_ids": []
    },
    {
      "chunk_id": "dc06d0ed-06fd-4f20-8316-e1a4bb41dbd0",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "block_ids": [
        "3652f1e6-e347-4443-935b-d7873e1f1b46",
        "f8a56c93-b06c-4904-b976-dbf9f7e83def"
      ],
      "content": "A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, \u0141. Kaiser, and I. Polosukhin, 'Attention is all you need,' Advances in neural information processing systems , vol. 30, 2017.\n\nC. Chen, X. Fan, C. Zheng, L. Xiao, M. Cheng, and C. Wang, 'Sdcae: Stack denoising convolutional autoencoder model for accident risk prediction via traffic big data,' in 2018 Sixth International Conference on Advanced Cloud and Big Data (CBD) . IEEE, 2018, pp. 328-333.",
      "image_ids": []
    },
    {
      "chunk_id": "4e168aa6-f618-4612-a13f-22f850693680",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "block_ids": [
        "bae45e18-646d-4488-8f5a-d9f8a588f9ee",
        "fb4e9215-2eb6-4999-aebf-6949099bfc2a"
      ],
      "content": "J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, 'Empirical evaluation of gated recurrent neural networks on sequence modeling,' arXiv preprint arXiv:1412.3555 , 2014.\n\nZ. Wu, S. Pan, G. Long, J. Jiang, and C. Zhang, 'Graph wavenet for deep spatial-temporal graph modeling,' arXiv preprint arXiv:1906.00121 , 2019.",
      "image_ids": []
    },
    {
      "chunk_id": "fe52e73c-bdd0-4a0a-8331-4cd26890f94d",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "block_ids": [
        "602834b5-8eaa-42e8-9161-27392a24bc0c",
        "68cbd1fe-dc49-469d-80fb-a0e2593f3db4"
      ],
      "content": "J. Bao, P. Liu, and S. V. Ukkusuri, 'A spatiotemporal deep learning approach for citywide short-term crash risk prediction with multi-source data,' Accident Analysis & Prevention , vol. 122, pp. 239-254, 2019.\n\nT.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Doll\u00b4 ar, 'Focal loss for dense object detection,' in Proceedings of the IEEE international conference on computer vision , 2017, pp. 2980-2988.",
      "image_ids": []
    },
    {
      "chunk_id": "87dd1641-cbed-4080-a2b8-93cb38886d0e",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 7,
      "section_id": "5597f229-f3be-4a4d-ae4b-60bf5d5b7a61",
      "block_ids": [
        "5bfc1d61-61ca-4360-b2e7-8d8dc53e6eb7"
      ],
      "content": "C. Ma, Y. Zhang, Q. Wang, and X. Liu, 'Point-of-interest recommendation: Exploiting self-attentive autoencoders with neighbor-aware influence,' in Proceedings of the 27th ACM International Conference on Information and Knowledge Management , 2018, pp. 697-706.",
      "image_ids": []
    }
  ],
  "images": [
    {
      "image_id": "dc5bdc1c-c8f8-45e6-9129-b8b9c2590ec5",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 1,
      "file_path": "",
      "bbox": [],
      "caption_raw": "",
      "caption_generated": null
    },
    {
      "image_id": "390c77ac-0d33-4384-978c-d223d7e6dc0f",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 2,
      "file_path": "",
      "bbox": [],
      "caption_raw": "",
      "caption_generated": null
    },
    {
      "image_id": "497c0dfc-d1d8-4104-8eb1-54e1bdc887db",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 3,
      "file_path": "",
      "bbox": [],
      "caption_raw": "",
      "caption_generated": null
    },
    {
      "image_id": "85cc7aa9-8ea4-4eb5-8c94-0e1f1b55cc07",
      "doc_id": "4a02bd17-9794-42dc-b6cc-6262b806d0a2",
      "page_no": 6,
      "file_path": "",
      "bbox": [],
      "caption_raw": "",
      "caption_generated": null
    }
  ]
}